{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ansi2html==1.9.1 (from -r requirements.txt (line 1))\n",
      "  Downloading ansi2html-1.9.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: asttokens==2.4.1 in c:\\users\\panst\\desktop\\4ml\\poker-game-analysis-with-plotly-dash-and-heroku\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (2.4.1)\n",
      "Collecting blinker==1.7.0 (from -r requirements.txt (line 3))\n",
      "  Downloading blinker-1.7.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting certifi==2023.11.17 (from -r requirements.txt (line 4))\n",
      "  Downloading certifi-2023.11.17-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting charset-normalizer==3.3.2 (from -r requirements.txt (line 5))\n",
      "  Using cached charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl.metadata (34 kB)\n",
      "Collecting click==8.1.7 (from -r requirements.txt (line 6))\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: colorama==0.4.6 in c:\\users\\panst\\desktop\\4ml\\poker-game-analysis-with-plotly-dash-and-heroku\\.venv\\lib\\site-packages (from -r requirements.txt (line 7)) (0.4.6)\n",
      "Collecting comm==0.2.1 (from -r requirements.txt (line 8))\n",
      "  Downloading comm-0.2.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting contourpy==1.2.0 (from -r requirements.txt (line 9))\n",
      "  Downloading contourpy-1.2.0-cp311-cp311-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting cycler==0.12.1 (from -r requirements.txt (line 10))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting dash==2.14.2 (from -r requirements.txt (line 11))\n",
      "  Downloading dash-2.14.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting dash-core-components==2.0.0 (from -r requirements.txt (line 12))\n",
      "  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting dash-html-components==2.0.0 (from -r requirements.txt (line 13))\n",
      "  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting dash-table==5.0.0 (from -r requirements.txt (line 14))\n",
      "  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting debugpy==1.8.0 (from -r requirements.txt (line 15))\n",
      "  Downloading debugpy-1.8.0-cp311-cp311-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: decorator==5.1.1 in c:\\users\\panst\\desktop\\4ml\\poker-game-analysis-with-plotly-dash-and-heroku\\.venv\\lib\\site-packages (from -r requirements.txt (line 16)) (5.1.1)\n",
      "Requirement already satisfied: executing==2.0.1 in c:\\users\\panst\\desktop\\4ml\\poker-game-analysis-with-plotly-dash-and-heroku\\.venv\\lib\\site-packages (from -r requirements.txt (line 17)) (2.0.1)\n",
      "Collecting Flask==3.0.0 (from -r requirements.txt (line 18))\n",
      "  Downloading flask-3.0.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting fonttools==4.47.0 (from -r requirements.txt (line 19))\n",
      "  Downloading fonttools-4.47.0-cp311-cp311-win_amd64.whl.metadata (160 kB)\n",
      "     ---------------------------------------- 0.0/160.4 kB ? eta -:--:--\n",
      "     -------------------------------------- 160.4/160.4 kB 4.8 MB/s eta 0:00:00\n",
      "Collecting gunicorn==21.2.0 (from -r requirements.txt (line 20))\n",
      "  Downloading gunicorn-21.2.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting idna==3.6 (from -r requirements.txt (line 21))\n",
      "  Using cached idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting importlib-metadata==7.0.1 (from -r requirements.txt (line 22))\n",
      "  Downloading importlib_metadata-7.0.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting ipykernel==6.28.0 (from -r requirements.txt (line 23))\n",
      "  Downloading ipykernel-6.28.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting ipython==8.19.0 (from -r requirements.txt (line 24))\n",
      "  Downloading ipython-8.19.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting itsdangerous==2.1.2 (from -r requirements.txt (line 25))\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: jedi==0.19.1 in c:\\users\\panst\\desktop\\4ml\\poker-game-analysis-with-plotly-dash-and-heroku\\.venv\\lib\\site-packages (from -r requirements.txt (line 26)) (0.19.1)\n",
      "Collecting Jinja2==3.1.2 (from -r requirements.txt (line 27))\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting joblib==1.3.2 (from -r requirements.txt (line 28))\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting jupyter_client==8.6.0 (from -r requirements.txt (line 29))\n",
      "  Downloading jupyter_client-8.6.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting jupyter_core==5.6.1 (from -r requirements.txt (line 30))\n",
      "  Downloading jupyter_core-5.6.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting kiwisolver==1.4.5 (from -r requirements.txt (line 31))\n",
      "  Using cached kiwisolver-1.4.5-cp311-cp311-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting MarkupSafe==2.1.3 (from -r requirements.txt (line 32))\n",
      "  Downloading MarkupSafe-2.1.3-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting matplotlib==3.8.2 (from -r requirements.txt (line 33))\n",
      "  Downloading matplotlib-3.8.2-cp311-cp311-win_amd64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in c:\\users\\panst\\desktop\\4ml\\poker-game-analysis-with-plotly-dash-and-heroku\\.venv\\lib\\site-packages (from -r requirements.txt (line 34)) (0.1.6)\n",
      "Collecting nest-asyncio==1.5.8 (from -r requirements.txt (line 35))\n",
      "  Downloading nest_asyncio-1.5.8-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting numpy==1.26.2 (from -r requirements.txt (line 36))\n",
      "  Downloading numpy-1.26.2-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.2/61.2 kB ? eta 0:00:00\n",
      "Collecting packaging==23.2 (from -r requirements.txt (line 37))\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pandas==2.1.4 (from -r requirements.txt (line 38))\n",
      "  Downloading pandas-2.1.4-cp311-cp311-win_amd64.whl.metadata (18 kB)\n",
      "Collecting parso==0.8.3 (from -r requirements.txt (line 39))\n",
      "  Downloading parso-0.8.3-py2.py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting pillow==10.2.0 (from -r requirements.txt (line 40))\n",
      "  Downloading pillow-10.2.0-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting platformdirs==4.1.0 (from -r requirements.txt (line 41))\n",
      "  Downloading platformdirs-4.1.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting plotly==5.18.0 (from -r requirements.txt (line 42))\n",
      "  Downloading plotly-5.18.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.43 in c:\\users\\panst\\desktop\\4ml\\poker-game-analysis-with-plotly-dash-and-heroku\\.venv\\lib\\site-packages (from -r requirements.txt (line 43)) (3.0.43)\n",
      "Collecting psutil==5.9.7 (from -r requirements.txt (line 44))\n",
      "  Downloading psutil-5.9.7-cp37-abi3-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: pure-eval==0.2.2 in c:\\users\\panst\\desktop\\4ml\\poker-game-analysis-with-plotly-dash-and-heroku\\.venv\\lib\\site-packages (from -r requirements.txt (line 45)) (0.2.2)\n",
      "Requirement already satisfied: Pygments==2.17.2 in c:\\users\\panst\\desktop\\4ml\\poker-game-analysis-with-plotly-dash-and-heroku\\.venv\\lib\\site-packages (from -r requirements.txt (line 46)) (2.17.2)\n",
      "Collecting pyparsing==3.1.1 (from -r requirements.txt (line 47))\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting python-dateutil==2.8.2 (from -r requirements.txt (line 48))\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting pytz==2023.3.post1 (from -r requirements.txt (line 49))\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: pyzmq==25.1.2 in c:\\users\\panst\\desktop\\4ml\\poker-game-analysis-with-plotly-dash-and-heroku\\.venv\\lib\\site-packages (from -r requirements.txt (line 50)) (25.1.2)\n",
      "Collecting requests==2.31.0 (from -r requirements.txt (line 51))\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting retrying==1.3.4 (from -r requirements.txt (line 52))\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting scikit-learn==1.3.2 (from -r requirements.txt (line 53))\n",
      "  Downloading scikit_learn-1.3.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting scipy==1.11.4 (from -r requirements.txt (line 54))\n",
      "  Downloading scipy-1.11.4-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 60.4/60.4 kB 3.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six==1.16.0 in c:\\users\\panst\\desktop\\4ml\\poker-game-analysis-with-plotly-dash-and-heroku\\.venv\\lib\\site-packages (from -r requirements.txt (line 55)) (1.16.0)\n",
      "Requirement already satisfied: stack-data==0.6.3 in c:\\users\\panst\\desktop\\4ml\\poker-game-analysis-with-plotly-dash-and-heroku\\.venv\\lib\\site-packages (from -r requirements.txt (line 56)) (0.6.3)\n",
      "Collecting tenacity==8.2.3 (from -r requirements.txt (line 57))\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting threadpoolctl==3.2.0 (from -r requirements.txt (line 58))\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: tornado==6.4 in c:\\users\\panst\\desktop\\4ml\\poker-game-analysis-with-plotly-dash-and-heroku\\.venv\\lib\\site-packages (from -r requirements.txt (line 59)) (6.4)\n",
      "Collecting traitlets==5.14.1 (from -r requirements.txt (line 60))\n",
      "  Downloading traitlets-5.14.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting typing_extensions==4.9.0 (from -r requirements.txt (line 61))\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting tzdata==2023.4 (from -r requirements.txt (line 62))\n",
      "  Downloading tzdata-2023.4-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting urllib3==2.1.0 (from -r requirements.txt (line 63))\n",
      "  Downloading urllib3-2.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting wcwidth==0.2.12 (from -r requirements.txt (line 64))\n",
      "  Downloading wcwidth-0.2.12-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting Werkzeug==3.0.1 (from -r requirements.txt (line 65))\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting zipp==3.17.0 (from -r requirements.txt (line 66))\n",
      "  Downloading zipp-3.17.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\panst\\desktop\\4ml\\poker-game-analysis-with-plotly-dash-and-heroku\\.venv\\lib\\site-packages (from dash==2.14.2->-r requirements.txt (line 11)) (65.5.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\panst\\desktop\\4ml\\poker-game-analysis-with-plotly-dash-and-heroku\\.venv\\lib\\site-packages (from jupyter_core==5.6.1->-r requirements.txt (line 30)) (306)\n",
      "Downloading ansi2html-1.9.1-py3-none-any.whl (17 kB)\n",
      "Downloading blinker-1.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "   ---------------------------------------- 0.0/162.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 162.5/162.5 kB 9.5 MB/s eta 0:00:00\n",
      "Using cached charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl (99 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 97.9/97.9 kB 5.5 MB/s eta 0:00:00\n",
      "Downloading comm-0.2.1-py3-none-any.whl (7.2 kB)\n",
      "Downloading contourpy-1.2.0-cp311-cp311-win_amd64.whl (187 kB)\n",
      "   ---------------------------------------- 0.0/187.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 187.6/187.6 kB 11.1 MB/s eta 0:00:00\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading dash-2.14.2-py3-none-any.whl (10.2 MB)\n",
      "   ---------------------------------------- 0.0/10.2 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.5/10.2 MB 32.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.0/10.2 MB 31.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.1/10.2 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.0/10.2 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.6/10.2 MB 25.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.5/10.2 MB 28.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.1/10.2 MB 29.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.2/10.2 MB 29.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.2/10.2 MB 28.4 MB/s eta 0:00:00\n",
      "Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
      "Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
      "Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
      "Downloading debugpy-1.8.0-cp311-cp311-win_amd64.whl (4.9 MB)\n",
      "   ---------------------------------------- 0.0/4.9 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 1.4/4.9 MB 45.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.1/4.9 MB 50.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.9/4.9 MB 39.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.9/4.9 MB 35.1 MB/s eta 0:00:00\n",
      "Downloading flask-3.0.0-py3-none-any.whl (99 kB)\n",
      "   ---------------------------------------- 0.0/99.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 99.7/99.7 kB ? eta 0:00:00\n",
      "Downloading fonttools-4.47.0-cp311-cp311-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 32.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 27.5 MB/s eta 0:00:00\n",
      "Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
      "   ---------------------------------------- 0.0/80.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 80.2/80.2 kB 4.4 MB/s eta 0:00:00\n",
      "Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
      "Downloading importlib_metadata-7.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading ipykernel-6.28.0-py3-none-any.whl (114 kB)\n",
      "   ---------------------------------------- 0.0/114.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 114.1/114.1 kB ? eta 0:00:00\n",
      "Downloading ipython-8.19.0-py3-none-any.whl (808 kB)\n",
      "   ---------------------------------------- 0.0/808.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 808.9/808.9 kB 25.0 MB/s eta 0:00:00\n",
      "Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.1/133.1 kB ? eta 0:00:00\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 302.2/302.2 kB 18.2 MB/s eta 0:00:00\n",
      "Downloading jupyter_client-8.6.0-py3-none-any.whl (105 kB)\n",
      "   ---------------------------------------- 0.0/105.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 105.9/105.9 kB 6.0 MB/s eta 0:00:00\n",
      "Downloading jupyter_core-5.6.1-py3-none-any.whl (28 kB)\n",
      "Using cached kiwisolver-1.4.5-cp311-cp311-win_amd64.whl (56 kB)\n",
      "Downloading MarkupSafe-2.1.3-cp311-cp311-win_amd64.whl (17 kB)\n",
      "Downloading matplotlib-3.8.2-cp311-cp311-win_amd64.whl (7.6 MB)\n",
      "   ---------------------------------------- 0.0/7.6 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.5/7.6 MB 46.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.0/7.6 MB 38.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.6/7.6 MB 36.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.4/7.6 MB 37.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.6 MB 37.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.6/7.6 MB 30.5 MB/s eta 0:00:00\n",
      "Downloading nest_asyncio-1.5.8-py3-none-any.whl (5.3 kB)\n",
      "Downloading numpy-1.26.2-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.8/15.8 MB 56.3 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.7/15.8 MB 39.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 5.5/15.8 MB 39.0 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 7.4/15.8 MB 43.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.2/15.8 MB 38.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.9/15.8 MB 36.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.3/15.8 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.6/15.8 MB 34.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.3/15.8 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 32.8 MB/s eta 0:00:00\n",
      "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "   ---------------------------------------- 0.0/53.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 53.0/53.0 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading pandas-2.1.4-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.9/10.6 MB 40.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.6/10.6 MB 38.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.8/10.6 MB 38.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.8/10.6 MB 36.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.4/10.6 MB 35.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.9/10.6 MB 35.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 31.2 MB/s eta 0:00:00\n",
      "Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
      "   ---------------------------------------- 0.0/100.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 100.8/100.8 kB 5.7 MB/s eta 0:00:00\n",
      "Downloading pillow-10.2.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.6/2.6 MB 34.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 33.5 MB/s eta 0:00:00\n",
      "Downloading platformdirs-4.1.0-py3-none-any.whl (17 kB)\n",
      "Downloading plotly-5.18.0-py3-none-any.whl (15.6 MB)\n",
      "   ---------------------------------------- 0.0/15.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.3/15.6 MB 41.6 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 3.1/15.6 MB 39.9 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.8/15.6 MB 43.4 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 6.0/15.6 MB 38.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.8/15.6 MB 38.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.5/15.6 MB 38.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.2/15.6 MB 36.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.0/15.6 MB 36.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.9/15.6 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.6/15.6 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.6/15.6 MB 34.4 MB/s eta 0:00:00\n",
      "Downloading psutil-5.9.7-cp37-abi3-win_amd64.whl (252 kB)\n",
      "   ---------------------------------------- 0.0/252.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 252.2/252.2 kB 15.1 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "   ---------------------------------------- 0.0/103.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 103.1/103.1 kB 6.2 MB/s eta 0:00:00\n",
      "Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "   ---------------------------------------- 0.0/247.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 247.7/247.7 kB 14.8 MB/s eta 0:00:00\n",
      "Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "   ---------------------------------------- 0.0/502.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 502.5/502.5 kB 30.8 MB/s eta 0:00:00\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Downloading scikit_learn-1.3.2-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "   ---------------------------------------- 0.0/9.2 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.4/9.2 MB 43.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.1/9.2 MB 39.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.7/9.2 MB 37.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.6/9.2 MB 38.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.2/9.2 MB 37.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.2 MB 36.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.2/9.2 MB 34.7 MB/s eta 0:00:00\n",
      "Downloading scipy-1.11.4-cp311-cp311-win_amd64.whl (44.1 MB)\n",
      "   ---------------------------------------- 0.0/44.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.4/44.1 MB 29.4 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 3.2/44.1 MB 33.9 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 4.9/44.1 MB 39.0 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 6.9/44.1 MB 36.6 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 8.3/44.1 MB 37.9 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 9.8/44.1 MB 37.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 11.6/44.1 MB 38.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 13.4/44.1 MB 38.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 15.2/44.1 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 16.7/44.1 MB 38.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 18.6/44.1 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 20.4/44.1 MB 40.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 22.1/44.1 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 23.8/44.1 MB 38.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 25.5/44.1 MB 38.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 27.4/44.1 MB 38.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 29.1/44.1 MB 38.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 30.7/44.1 MB 38.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 32.5/44.1 MB 38.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 34.4/44.1 MB 38.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 36.1/44.1 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.1/44.1 MB 38.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.6/44.1 MB 38.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.4/44.1 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.2/44.1 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.1/44.1 MB 29.7 MB/s eta 0:00:00\n",
      "Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Downloading traitlets-5.14.1-py3-none-any.whl (85 kB)\n",
      "   ---------------------------------------- 0.0/85.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 85.4/85.4 kB ? eta 0:00:00\n",
      "Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Downloading tzdata-2023.4-py2.py3-none-any.whl (346 kB)\n",
      "   ---------------------------------------- 0.0/346.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 346.6/346.6 kB 21.0 MB/s eta 0:00:00\n",
      "Downloading urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "   ---------------------------------------- 0.0/104.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 104.6/104.6 kB ? eta 0:00:00\n",
      "Downloading wcwidth-0.2.12-py2.py3-none-any.whl (34 kB)\n",
      "Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "   ---------------------------------------- 0.0/226.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 226.7/226.7 kB ? eta 0:00:00\n",
      "Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Installing collected packages: wcwidth, pytz, dash-table, dash-html-components, dash-core-components, zipp, urllib3, tzdata, typing_extensions, traitlets, threadpoolctl, tenacity, retrying, python-dateutil, pyparsing, psutil, platformdirs, pillow, parso, packaging, numpy, nest-asyncio, MarkupSafe, kiwisolver, joblib, itsdangerous, idna, fonttools, debugpy, cycler, click, charset-normalizer, certifi, blinker, ansi2html, Werkzeug, scipy, requests, plotly, pandas, jupyter_core, Jinja2, importlib-metadata, gunicorn, contourpy, comm, scikit-learn, matplotlib, jupyter_client, ipython, Flask, ipykernel, dash\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.2.13\n",
      "    Uninstalling wcwidth-0.2.13:\n",
      "      Successfully uninstalled wcwidth-0.2.13\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 5.14.2\n",
      "    Uninstalling traitlets-5.14.2:\n",
      "      Successfully uninstalled traitlets-5.14.2\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.9.8\n",
      "    Uninstalling psutil-5.9.8:\n",
      "      Successfully uninstalled psutil-5.9.8\n",
      "  Attempting uninstall: platformdirs\n",
      "    Found existing installation: platformdirs 4.2.0\n",
      "    Uninstalling platformdirs-4.2.0:\n",
      "      Successfully uninstalled platformdirs-4.2.0\n",
      "  Attempting uninstall: parso\n",
      "    Found existing installation: parso 0.8.4\n",
      "    Uninstalling parso-0.8.4:\n",
      "      Successfully uninstalled parso-0.8.4\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.0\n",
      "    Uninstalling packaging-24.0:\n",
      "      Successfully uninstalled packaging-24.0\n",
      "  Attempting uninstall: nest-asyncio\n",
      "    Found existing installation: nest-asyncio 1.6.0\n",
      "    Uninstalling nest-asyncio-1.6.0:\n",
      "      Successfully uninstalled nest-asyncio-1.6.0\n",
      "  Attempting uninstall: debugpy\n",
      "    Found existing installation: debugpy 1.8.1\n",
      "    Uninstalling debugpy-1.8.1:\n",
      "      Successfully uninstalled debugpy-1.8.1\n",
      "  Attempting uninstall: jupyter_core\n",
      "    Found existing installation: jupyter_core 5.7.2\n",
      "    Uninstalling jupyter_core-5.7.2:\n",
      "      Successfully uninstalled jupyter_core-5.7.2\n",
      "  Attempting uninstall: comm\n",
      "    Found existing installation: comm 0.2.2\n",
      "    Uninstalling comm-0.2.2:\n",
      "      Successfully uninstalled comm-0.2.2\n",
      "  Attempting uninstall: jupyter_client\n",
      "    Found existing installation: jupyter_client 8.6.1\n",
      "    Uninstalling jupyter_client-8.6.1:\n",
      "      Successfully uninstalled jupyter_client-8.6.1\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 8.23.0\n",
      "    Uninstalling ipython-8.23.0:\n",
      "      Successfully uninstalled ipython-8.23.0\n",
      "  Attempting uninstall: ipykernel\n",
      "    Found existing installation: ipykernel 6.29.4\n",
      "    Uninstalling ipykernel-6.29.4:\n",
      "      Successfully uninstalled ipykernel-6.29.4\n",
      "Successfully installed Flask-3.0.0 Jinja2-3.1.2 MarkupSafe-2.1.3 Werkzeug-3.0.1 ansi2html-1.9.1 blinker-1.7.0 certifi-2023.11.17 charset-normalizer-3.3.2 click-8.1.7 comm-0.2.1 contourpy-1.2.0 cycler-0.12.1 dash-2.14.2 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 debugpy-1.8.0 fonttools-4.47.0 gunicorn-21.2.0 idna-3.6 importlib-metadata-7.0.1 ipykernel-6.28.0 ipython-8.19.0 itsdangerous-2.1.2 joblib-1.3.2 jupyter_client-8.6.0 jupyter_core-5.6.1 kiwisolver-1.4.5 matplotlib-3.8.2 nest-asyncio-1.5.8 numpy-1.26.2 packaging-23.2 pandas-2.1.4 parso-0.8.3 pillow-10.2.0 platformdirs-4.1.0 plotly-5.18.0 psutil-5.9.7 pyparsing-3.1.1 python-dateutil-2.8.2 pytz-2023.3.post1 requests-2.31.0 retrying-1.3.4 scikit-learn-1.3.2 scipy-1.11.4 tenacity-8.2.3 threadpoolctl-3.2.0 traitlets-5.14.1 typing_extensions-4.9.0 tzdata-2023.4 urllib3-2.1.0 wcwidth-0.2.12 zipp-3.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The candidate selected for download or install is a yanked version: 'ipython' candidate (version 8.19.0 at https://files.pythonhosted.org/packages/1d/c6/c29c0509ce3235fa392779db476396e7e5d0a9c854967fdf411f168187a5/ipython-8.19.0-py3-none-any.whl (from https://pypi.org/simple/ipython/) (requires-python:>=3.10))\n",
      "Reason for being yanked: Promt continuation function signature change breeak sagemath. See https://github.com/ipython/ipython/issues/14273\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\PanSt\\Desktop\\4ML\\Poker-Game-Analysis-with-Plotly-Dash-and-Heroku\\.venv\\Lib\\site-packages\\~sutil'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\PanSt\\Desktop\\4ML\\Poker-Game-Analysis-with-Plotly-Dash-and-Heroku\\.venv\\Lib\\site-packages\\~ebugpy'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "\n",
    "import dash\n",
    "from dash import Dash, dash_table\n",
    "from dash import html\n",
    "from dash import dcc\n",
    "from dash.dependencies import Output, Input, State\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# heroku csv reading function\\ndef load_data(data_file: str) -> pd.DataFrame:\\n    \\'\\'\\'\\n    Load data from /data directory\\n    \\'\\'\\'\\n    PATH = pathlib.Path(__file__).parent\\n    DATA_PATH = PATH.joinpath(\"data\").resolve()\\n    return pd.read_csv(DATA_PATH.joinpath(data_file))'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "import os\n",
    "\n",
    "\"\"\"# heroku csv reading function\n",
    "def load_data(data_file: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    Load data from /data directory\n",
    "    '''\n",
    "    PATH = pathlib.Path(__file__).parent\n",
    "    DATA_PATH = PATH.joinpath(\"data\").resolve()\n",
    "    return pd.read_csv(DATA_PATH.joinpath(data_file))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df = pd.read_excel(\"Poker League 2023.xlsx\", index_col=0) # read from excel file\\ndf.to_csv(\"data/data.csv\") # convert to csv and upload to the relevant directory'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"df = pd.read_excel(\"Poker League 2023.xlsx\", index_col=0) # read from excel file\n",
    "df.to_csv(\"data/data.csv\") # convert to csv and upload to the relevant directory\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "df = pd.read_csv(\"data/data.csv\")\n",
    "df.set_index('Unnamed: 0', inplace=True)\n",
    "df.rename_axis(None, inplace=True) #remove index header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Year List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the unique years and sort them\n",
    "unique_years = df.iloc[:,3:].T.index.str.extract(r'(\\d{4})').squeeze().unique().astype(int)\n",
    "yearlist = np.sort(unique_years)[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Namelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "namelist = ['Panos', 'Ashish', 'Kartik', 'Akshaye', 'Chris', 'Sid', 'Tanish', 'Yufeng', 'Soumil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_selected_year(df, selected_year):\n",
    "    selected_year = str(selected_year)\n",
    "    df = df.filter(like=selected_year, axis=1) # get only columns of the selected year\n",
    "    df.insert(0, 'NET', df.sum(axis=1))\n",
    "    df.insert(1, 'PPG', df.iloc[:,1:].mean(axis=1))\n",
    "    df.insert(2, 'TABLES', df.iloc[:,2:].count(axis=1))\n",
    "\n",
    "    dftime2 = df.iloc[:,3:].T.copy() # to be used for personal form calculation\n",
    "    dftime3 = dftime2.copy() # to be used for global form calculation\n",
    "    df.fillna(0, inplace=True)\n",
    "    dftime = df.iloc[:,2:].T.copy()\n",
    "    \n",
    "################################################################################\n",
    "\n",
    "    # Preprocessing for profit/loss against time analysis\n",
    "    other_players = [col for col in dftime.columns if col not in namelist] # Create a list of players not in the selected list\n",
    "    dftime['Guests'] = dftime[other_players].sum(axis=1).to_frame() # sum all guest values\n",
    "    dftime.drop(columns=other_players, inplace=True) # drop the other players\n",
    "\n",
    "    if 'TABLES' in dftime.index:\n",
    "        dftime.drop(index='TABLES', inplace=True)\n",
    "        \n",
    "    dftime = dftime.rename_axis('Date').reset_index()\n",
    "\n",
    "################################################################################\n",
    "\n",
    "    # Initialize variables to keep track of cumulative sums for each column\n",
    "    cumulative_sums = {col: 0 for col in dftime.columns[1:]}\n",
    "\n",
    "    # Iterate through the columns and update values so that the datum of the nth row is the sum of all data up to and including row n \n",
    "    for col in dftime.columns[1:]:\n",
    "        for index, row in dftime.iterrows():\n",
    "            cumulative_sums[col] += row[col]\n",
    "            dftime.at[index, col] = cumulative_sums[col]\n",
    "\n",
    "    # Convert 'Date' column to datetime format\n",
    "    dftime['Date'] = pd.to_datetime(dftime['Date'], format='%d/%m/%Y')\n",
    "\n",
    "    # Format the 'Date' column\n",
    "    dftime['Date'] = dftime['Date'].dt.strftime('%d-%b')\n",
    "\n",
    "    return df, dftime, dftime2, dftime3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '12-Jan - Session 1', 'value': 0},\n",
       " {'label': '16-Jan - Session 2', 'value': 1},\n",
       " {'label': '18-Jan - Session 3', 'value': 2},\n",
       " {'label': '28-Jan - Session 4', 'value': 3},\n",
       " {'label': '06-Feb - Session 5', 'value': 4},\n",
       " {'label': '10-Feb - Session 6', 'value': 5},\n",
       " {'label': '16-Feb - Session 7', 'value': 6}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2, dftime, dftime2, dftime3 = df_selected_year(df=df, selected_year=2024)\n",
    "updated_options = [{'label': '{1} - Session {0}'.format(i+1, pd.to_datetime(dftime2.index.values[i], format='%d/%m/%Y').strftime('%d-%b')), 'value': i} for i in range(dftime2.shape[0])]\n",
    "updated_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for profit/loss against time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_data(dftime):\n",
    "    dftime_melt = dftime.melt(id_vars='Date', value_vars=list(dftime.columns[1:])).rename({'variable':'Player','value':'Net Profit/Loss'}, axis='columns') #melt the table and rename the new columns\n",
    "    dftime_melt['Net Profit/Loss'] = round(dftime_melt['Net Profit/Loss'],2) # round all values to 2 decimal points\n",
    "    return dftime_melt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Analysis\n",
    "\n",
    "# Session Results\n",
    "def make_table(row, selected_year, df_raw):\n",
    "    # Get date of the selected year only\n",
    "    df, dftime, dftime2, dftime3 = df_selected_year(df=df_raw, selected_year=selected_year)\n",
    "\n",
    "    selected_data = dftime2.iloc[row:row + 1].dropna(axis=1).to_dict('records')\n",
    "    fig = dash_table.DataTable(\n",
    "        id='results-table',  # Specify the id for the DataTable\n",
    "        columns=[{'name': col, 'id': col} for col in dftime2.iloc[row:row + 1].dropna(axis=1).columns],\n",
    "        data=selected_data,\n",
    "        style_table={'fontSize': 22},  # Set the font size\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year Stats\n",
    "\n",
    "def year_table_stats(selected_year, df_raw):\n",
    "    df2, dftime, dftime2, dftime3 = df_selected_year(df=df_raw, selected_year=selected_year)\n",
    "    \n",
    "    df2 = df2.loc[namelist]\n",
    "    df2 = df2.iloc[:,:3]\n",
    "    df2 = df2.astype(float)\n",
    "    df2 = df2.reset_index().rename(columns={'index':'Player', 'NET': 'Net Profit', 'PPG': 'Profit per Game', 'TABLES': 'Games Played'}).sort_values(by='Net Profit')\n",
    "    df2 = df2.sort_values(by='Net Profit', ascending=False)\n",
    "    df2['Profit per Game'] = df2['Profit per Game'].apply(lambda x: f'{x:.2f}')\n",
    "    df2['Net Profit'] = df2['Net Profit'].apply(lambda x: f'{x:.2f}')\n",
    "    data = df2.to_dict(orient='records')\n",
    "\n",
    "    fig = dash_table.DataTable(\n",
    "        columns=[{'name': col, 'id': col} for col in df2.columns],\n",
    "        data=data,\n",
    "        style_table={'fontSize': 22},\n",
    "        style_data={'whiteSpace': 'normal', 'height': 'auto'},\n",
    "        style_cell={'textAlign': 'center', 'padding': '10px'},   \n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Time Stats\n",
    "\n",
    "def all_time_table_stats(df_raw):\n",
    "    df2 = df_raw.iloc[:, 3:].copy()\n",
    "\n",
    "    df2.insert(0, 'NET', df2.sum(axis=1))\n",
    "    df2.insert(1, 'PPG', df2.iloc[:,1:].mean(axis=1))\n",
    "    df2.insert(2, 'TABLES', df2.iloc[:,2:].count(axis=1))\n",
    "    df2.fillna(0, inplace=True)\n",
    "\n",
    "    df2 = df2.loc[namelist]\n",
    "    df2 = df2.iloc[:,:3]\n",
    "    df2 = df2.astype(float)\n",
    "    df2 = df2.reset_index().rename(columns={'index':'Player', 'NET': 'Net Profit', 'PPG': 'Profit per Game', 'TABLES': 'Games Played'}).sort_values(by='Net Profit')\n",
    "    df2 = df2.sort_values(by='Net Profit', ascending=False)\n",
    "    df2['Profit per Game'] = df2['Profit per Game'].apply(lambda x: f'{x:.2f}')\n",
    "    df2['Net Profit'] = df2['Net Profit'].apply(lambda x: f'{x:.2f}')\n",
    "    data = df2.to_dict(orient='records')\n",
    "\n",
    "    fig = dash_table.DataTable(\n",
    "        columns=[{'name': col, 'id': col} for col in df2.columns],\n",
    "        data=data,\n",
    "        style_table={'fontSize': 22},\n",
    "        style_data={'whiteSpace': 'normal', 'height': 'auto'},\n",
    "        style_cell={'textAlign': 'center', 'padding': '10px'},   \n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current Profit/Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current Profit/Loss\n",
    "def Status_bar(player_list, selected_year, df_raw):\n",
    "    # Get date of the selected year only\n",
    "    df, dftime, dftime2, dftime3 = df_selected_year(df=df_raw, selected_year=selected_year)\n",
    "\n",
    "    data = [round(value, 2) for value in dftime.loc[dftime.index[-1], player_list].tolist()] #get the current p/l from the last row of the dataframe\n",
    "    \n",
    "    # Create a DataFrame for the bar chart\n",
    "    df = pd.DataFrame({'Player': player_list, 'Net Profit/Loss': data})\n",
    "    \n",
    "    # Create the bar chart with Plotly Express\n",
    "    fig = px.bar(df, x='Net Profit/Loss', y='Player', text='Net Profit/Loss', orientation='h')\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_title='Net Profit/Loss',\n",
    "        yaxis_title='Player',\n",
    "        xaxis=dict(\n",
    "            tickformat=\"%b\",\n",
    "            showgrid=True,\n",
    "            tickfont = {'size':16},\n",
    "        ),\n",
    "        title_x=0.5,\n",
    "        title_font = {'size':20},\n",
    "        yaxis=dict(\n",
    "            tickfont = {'size':16},\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Show values next to bars\n",
    "    fig.update_traces(texttemplate='%{text:.2f}', textposition='outside')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Lapse Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Lapse Bar Plot\n",
    "def Time_Lapse(player_list, selected_year, df_raw):\n",
    "    # Get date of the selected year only\n",
    "    df, dftime, dftime2, dftime3 = df_selected_year(df=df_raw, selected_year=selected_year)\n",
    "\n",
    "    dftime_melt = melt_data(dftime)\n",
    "    dftime_melt = dftime_melt[dftime_melt['Player'].isin(player_list)] #update the dataframe to include only the names selected\n",
    "\n",
    "    max_value = dftime_melt['Net Profit/Loss'].max()//50*50+50\n",
    "    min_value = dftime_melt['Net Profit/Loss'].min()//50*50\n",
    "\n",
    "    fig = px.bar(dftime_melt,  \n",
    "                x='Net Profit/Loss', y = \"Player\", animation_frame=\"Date\", height=600, hover_data=['Net Profit/Loss'],color='Net Profit/Loss', orientation= 'h', range_x=(min_value, max_value))\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Net Profit/Loss\",\n",
    "        xaxis=dict(\n",
    "            tickformat=\"%b\",\n",
    "            showgrid=True,\n",
    "            tickfont = {'size':16},\n",
    "        ),\n",
    "        title_x=0.5,\n",
    "        title_font = {'size':20},\n",
    "        yaxis=dict(\n",
    "            tickfont = {'size':16},\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_traces(textfont_size=12, textangle=0, textposition=\"outside\",overwrite=True, )  \n",
    "    fig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 600\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Player Analysis\n",
    "def Current_profit_loss(person, selected_year, df_raw):\n",
    "    # Get date of the selected year only\n",
    "    df, dftime, dftime2, dftime3 = df_selected_year(df=df_raw, selected_year=selected_year)\n",
    "\n",
    "    def get_ppg(person): # find the previous profit per game statistic\n",
    "        ppg = df.loc[person]['PPG']\n",
    "        games_played = df.loc[person]['TABLES']\n",
    "        last_p_l = df.at[person, df.columns[-1]]\n",
    "        net = dftime.loc[dftime.index[-1], person]\n",
    "        (ppg_ref := ppg) if np.isnan(dftime2[person].tail(1).values) else (ppg_ref := (net - last_p_l) / (games_played - 1))\n",
    "        return round(ppg_ref, 1)\n",
    "    \n",
    "    def get_position(dftime, person):\n",
    "        position = dftime.iloc[-1,1:-1].rank(ascending=False)\n",
    "        position = int(position[person])\n",
    "        reference_pos = dftime.iloc[-2,1:-1].rank(ascending=False)\n",
    "        reference_pos = int(reference_pos[person])\n",
    "        return position, reference_pos\n",
    "    \n",
    "    # Create a subplot grid with 1 row and 4 columns\n",
    "    fig = make_subplots(rows=1, cols=4)\n",
    "    \n",
    "    # Define data for the first gauge chart\n",
    "    trace1 = (go.Indicator(\n",
    "        mode = \"number+delta\",\n",
    "        value= get_position(dftime, person)[0],\n",
    "        title={'text': \"Ranking\"},\n",
    "        delta= {'reference': 2*get_position(dftime, person)[0] - get_position(dftime, person)[1], 'increasing': {'color': \"#006C5B\"}, 'decreasing': {'color': \"red\"}},\n",
    "        )) # to reverse the sign of the reference number: -difference = (final-reference)+final = 2*final-reference\n",
    "\n",
    "    # Define data for the second gauge chart\n",
    "    trace2 = (go.Indicator(\n",
    "        mode = \"number+delta\",\n",
    "        value= int(dftime.loc[dftime.index[-1], person]), #Take the last value of the column\n",
    "        title={'text': \"Net Profit/Loss\"},\n",
    "        delta= {'reference': int(dftime.loc[dftime.index[-2], person]), 'increasing': {'color': \"#006C5B\"}, 'decreasing': {'color': \"red\"}},\n",
    "        ))\n",
    "\n",
    "    # Define data for the third gauge chart\n",
    "    trace3 = (go.Indicator(\n",
    "        mode = \"number+delta\",\n",
    "        value= round(df.loc[person]['PPG'], 1), # ppg as defined by the first table\n",
    "        title={'text': \"Profit per Game\"},\n",
    "        delta= {'reference': get_ppg(person), 'increasing': {'color': \"#006C5B\"}, 'decreasing': {'color': \"red\"}},\n",
    "        ))\n",
    "\n",
    "    # Define data for the fourth gauge chart\n",
    "    trace4 = (go.Indicator(\n",
    "        mode = \"number+delta\",\n",
    "        value= int(df.loc[person]['TABLES']), # ppg as defined by the first table\n",
    "        title={'text': \"Games Played\"},\n",
    "        delta={'reference': int(df.loc[person]['TABLES'] - df_raw.loc[person].tail(1).notna().values), \n",
    "               'increasing': {'color': \"#006C5B\"}, 'decreasing': {'color': \"red\"}},\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(paper_bgcolor = \"lavender\", font = {'color': \"darkblue\", 'family': \"Arial\"})\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1,\n",
    "        cols=4,\n",
    "        specs=[[{'type' : 'indicator'}, {'type' : 'indicator'}, {'type': 'indicator'}, {'type' : 'indicator'}]],\n",
    "        )\n",
    "\n",
    "    fig.append_trace(trace1, row=1, col=1)\n",
    "    fig.append_trace(trace2, row=1, col=2)\n",
    "    fig.append_trace(trace3, row=1, col=3)\n",
    "    fig.append_trace(trace4, row=1, col=4)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session Progress Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session Progress Plot\n",
    "def Progress_Session(player_list, person, selected_year, df_raw):\n",
    "    # Get date of the selected year only\n",
    "    df, dftime, dftime2, dftime3 = df_selected_year(df=df_raw, selected_year=selected_year)\n",
    "\n",
    "    x_data = np.arange(1, len(dftime[person]) + 1)\n",
    "\n",
    "    fig = px.line() #initialise figure\n",
    "\n",
    "    # Add the player data line first\n",
    "    player_line = go.Scatter(x=x_data, y=dftime[person], mode='lines', name='Actual ({})'.format(person), line=dict(color='blue'))\n",
    "    fig.add_trace(player_line)\n",
    "\n",
    "    # Add the 5-day average data\n",
    "    if dftime.shape[0] >= 6:\n",
    "        average_5_game = go.Scatter(x=np.arange(3, dftime[person].shape[0]-1, 1), y=dftime[person].rolling(window=5).mean().dropna().values, mode='lines', name='5-game avg ({})'.format(person), line=dict(color='black'))\n",
    "        fig.add_trace(average_5_game)\n",
    "    \n",
    "    # Add the progress lines of each other player, truncate to 7 players\n",
    "    color_palette = ['red', 'purple', 'orange', 'pink', 'gray', 'brown', 'green', 'yellow'] # define color palette\n",
    "\n",
    "    for player in range(len(player_list[:8])):\n",
    "        player_line = go.Scatter(x=x_data, y=dftime[player_list[player]], mode='lines', name=player_list[player], line=dict(color=color_palette[player]))\n",
    "        fig.add_trace(player_line)\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title='Session Number ({})'.format(selected_year),\n",
    "        yaxis_title='Net Profit/Loss',\n",
    "        xaxis=dict(\n",
    "            tickformat=\"%b\",\n",
    "            showgrid=True,\n",
    "            tickfont = {'size':16},\n",
    "        ),\n",
    "        title_x=0.5,\n",
    "        title_font = {'size':20},\n",
    "        yaxis=dict(\n",
    "            tickfont = {'size':16},\n",
    "        )\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Progress Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly Progress Plot\n",
    "def Progress_Monthly(player_list, person, selected_year, df_raw):  \n",
    "    # Get date of the selected year only\n",
    "    df, dftime, dftime2, dftime3 = df_selected_year(df=df_raw, selected_year=selected_year)\n",
    "\n",
    "    x_data = pd.to_datetime(dftime['Date'] + f\"-{selected_year}\", format='%d-%b-%Y')\n",
    "\n",
    "    fig = px.line() #initialise figure\n",
    "\n",
    "    # Add the player data line\n",
    "    player_line = go.Scatter(x=x_data, y=dftime[person], mode='lines', name='({})'.format(person), line=dict(color='blue'))\n",
    "    fig.add_trace(player_line)\n",
    "\n",
    "    # Add the progress lines of each other player, truncate to 7 players\n",
    "    color_palette = ['red', 'purple', 'orange', 'pink', 'gray', 'brown', 'green', 'yellow'] # define color palette\n",
    "\n",
    "    for player in range(len(player_list[:8])):\n",
    "        player_line = go.Scatter(x=x_data, y=dftime[player_list[player]], mode='lines', name=player_list[player], line=dict(color=color_palette[player]))\n",
    "        fig.add_trace(player_line)\n",
    "\n",
    "    # Customize the layout, including the title\n",
    "    fig.update_layout(\n",
    "        xaxis_title='Month ({})'.format(selected_year),\n",
    "        yaxis_title='Net Profit/Loss',\n",
    "        xaxis=dict(\n",
    "            tickformat=\"%b\",\n",
    "            showgrid=True,\n",
    "            tickfont = {'size':16},\n",
    "        ),\n",
    "        title_x=0.5,\n",
    "        title_font = {'size':20},\n",
    "        yaxis=dict(\n",
    "            tickfont = {'size':16},\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player Distrubition Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution(player_list, person, df):\n",
    "    def get_data(player):\n",
    "        df_data_person = df.iloc[:,3:].T\n",
    "        df_data_person = df_data_person[[player]].dropna()\n",
    "        return df_data_person[player]\n",
    "\n",
    "    hist_data = [get_data(person)]\n",
    "    for player in player_list:\n",
    "        hist_data += [get_data(player)]\n",
    "\n",
    "    group_labels = [person] + player_list\n",
    "    color_palette = ['blue', 'red', 'purple', 'orange', 'pink', 'gray', 'brown', 'green', 'yellow']\n",
    "\n",
    "    fig = ff.create_distplot(hist_data, group_labels, show_hist=False, colors=color_palette)\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(title='Profit/Loss', title_font=dict(size=16)),\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_history(selected_player, df_raw):\n",
    "    df_data_person = df.iloc[:,3:].T\n",
    "    df_data_person.index = pd.to_datetime(df_data_person.index, dayfirst=True).strftime('%y%m%d') #convert to this format to sort the dates\n",
    "    df_data_person = df_data_person.sort_index(ascending=False)\n",
    "    df_data_person.index = pd.to_datetime(df_data_person.index, format='%y%m%d').strftime('%b-%d %Y')\n",
    "    df_data_person = df_data_person[[selected_player]].dropna()\n",
    "    df_data_person.reset_index(inplace=True)\n",
    "    df_data_person.rename(columns={'index':'Date', selected_player:'Profit'}, inplace=True)\n",
    "\n",
    "    # Convert the 'Profit' column to numeric and round to two decimal places\n",
    "    df_data_person['Profit'] = df_data_person['Profit'].apply(lambda x: f'{x:.2f}')\n",
    "\n",
    "    data = df_data_person.to_dict(orient='records')\n",
    "    fig = dash_table.DataTable(\n",
    "        # dont include ID here; it will prevent the page from refreshing\n",
    "        columns=[\n",
    "            {'name': 'Date', 'id': 'Date'},\n",
    "            {'name': 'Profit', 'id': 'Profit', 'format': dash_table.Format.Format(precision=2)}\n",
    "        ],\n",
    "        data=data,\n",
    "        style_table={'fontSize': 30},\n",
    "        style_data={'whiteSpace': 'normal', 'height': 'auto'},\n",
    "        style_cell={'textAlign': 'center', 'padding': '10px'},\n",
    "        style_data_conditional=[\n",
    "            {\n",
    "                'if': {'column_id': 'Profit', 'filter_query': '{Profit} < 0'},\n",
    "                'color': 'red'\n",
    "            },\n",
    "            {\n",
    "                'if': {'column_id': 'Profit', 'filter_query': '{Profit} > 0'},\n",
    "                'color': '#006C5B'\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal and Global Form Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personal and Global Form Preprocessing\n",
    "def Form_Preprocessing(person, dftime2, dftime3):    \n",
    "    # Personal Form\n",
    "    dftime5 = dftime2[person].dropna()\n",
    "    n = 4\n",
    "    dftime5 = pd.Series([sum(dftime5[i:i+n]) for i in range(0, len(dftime5)-n+1, 1)]) # sum n in a row together\n",
    "    x = np.array(dftime5).reshape(-1,1) #reshape to fit transform\n",
    "    filtered_data = StandardScaler().fit_transform(x) #normalise first \n",
    "    filtered_data = MinMaxScaler().fit_transform(filtered_data)*10 #convert normalised data into min, max\n",
    "    filtered_data = [np.round(datum * 10) / 10 for datum in filtered_data]\n",
    "\n",
    "    # Global Form\n",
    "    # normalise the performance of all players in the playerlist based on the performance of these people:\n",
    "    dftime3 = dftime3[dftime3.columns[dftime3.columns.isin(namelist)]] \n",
    "    if 'TABLES' in dftime3.index:  \n",
    "        dftime3.drop(index='TABLES' , inplace= True) #drop row with the number of tables\n",
    "    person_column = dftime3.pop(person)\n",
    "    dftime3[person] = person_column\n",
    "    global_list = []\n",
    "    for column in dftime3:\n",
    "        dftime4 = dftime3[column].dropna() #drop all NaN values\n",
    "        global_list.extend(pd.Series([sum(dftime4[i:i+n]) for i in range(0, len(dftime4)-n+1, 1)])) # sum 3 in a row together\n",
    "    filtered_data2 = StandardScaler().fit_transform(np.array(global_list).reshape(-1, 1)) #normalise first \n",
    "    filtered_data2 = MinMaxScaler().fit_transform(filtered_data2)*10 #convert normalised data into min, max\n",
    "    filtered_data2 = [np.round(datum * 10) / 10 for datum in filtered_data2] #round data\n",
    "    \n",
    "    return filtered_data, filtered_data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal and Global Form Gauge charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personal and Global Form Gauge charts\n",
    "def Gauge_Charts(person, selected_year, df):\n",
    "    # Get date of the selected year only\n",
    "    df, dftime, dftime2, dftime3 = df_selected_year(df=df, selected_year=selected_year)\n",
    "\n",
    "    filtered_data, filtered_data2 = Form_Preprocessing(person, dftime2, dftime3)\n",
    "    \n",
    "    # Create a subplot grid with 1 row and 2 columns\n",
    "    fig = make_subplots(rows=1, cols=2)\n",
    "\n",
    "    # Define data for the first gauge chart\n",
    "    trace1 = (go.Indicator(\n",
    "        mode = \"gauge+number+delta\",\n",
    "        value = float(filtered_data[-1][0]),\n",
    "        domain = {'x': [0, 1], 'y': [0, 1]},\n",
    "        title = {'text': \"{} Personal Form\".format(person), 'font': {'size': 20}},\n",
    "        delta = {'reference': int(filtered_data[-2][0]), 'increasing': {'color': \"RebeccaPurple\"}},\n",
    "        gauge = {\n",
    "            'axis': {'range': [None, 10], 'tickwidth': 1, 'tickcolor': \"darkblue\"},\n",
    "            'bar': {'color': \"darkblue\"},\n",
    "            'bgcolor': \"white\",\n",
    "            'borderwidth': 2,\n",
    "            'bordercolor': \"gray\",\n",
    "            'steps': [\n",
    "                {'range': [0, 5], 'color': 'red'},\n",
    "                {'range': [5, 10], 'color': 'cyan'}],\n",
    "            }))\n",
    "\n",
    "    # Define data for the second gauge chart\n",
    "    trace2 = (go.Indicator(\n",
    "        mode = \"gauge+number+delta\",\n",
    "        value = float(filtered_data2[-1][0]),\n",
    "        domain = {'x': [0, 1], 'y': [0, 1]},\n",
    "        title = {'text': \"{} Global Form\".format(person), 'font': {'size': 20}},\n",
    "        delta = {'reference': int(filtered_data2[-2][0]), 'increasing': {'color': \"RebeccaPurple\"}},\n",
    "        gauge = {\n",
    "            'axis': {'range': [None, 10], 'tickwidth': 1, 'tickcolor': \"darkblue\"},\n",
    "            'bar': {'color': \"darkblue\"},\n",
    "            'bgcolor': \"white\",\n",
    "            'borderwidth': 2,\n",
    "            'bordercolor': \"gray\",\n",
    "            'steps': [\n",
    "                {'range': [0, 5], 'color': 'red'},\n",
    "                {'range': [5, 10], 'color': 'cyan'}],\n",
    "            }))\n",
    "\n",
    "    fig.update_layout(\n",
    "        paper_bgcolor = \"lavender\",\n",
    "        font = {'color': \"darkblue\", 'family': \"Arial\"})\n",
    "    fig = make_subplots(\n",
    "        rows=1,\n",
    "        cols=2,\n",
    "        specs=[[{'type' : 'indicator'}, {'type' : 'indicator'}]],\n",
    "        )\n",
    "\n",
    "    fig.append_trace(trace1, row=1, col=1)\n",
    "    fig.append_trace(trace2, row=1, col=2)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dash Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8060/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x233007e07d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PanSt\\AppData\\Local\\Temp\\ipykernel_20940\\1365882306.py:53: DeprecationWarning:\n",
      "\n",
      "Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "\n",
      "C:\\Users\\PanSt\\AppData\\Local\\Temp\\ipykernel_20940\\2264318532.py:132: FutureWarning:\n",
      "\n",
      "Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "\n",
      "C:\\Users\\PanSt\\AppData\\Local\\Temp\\ipykernel_20940\\1365882306.py:53: DeprecationWarning:\n",
      "\n",
      "Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "\n",
      "C:\\Users\\PanSt\\AppData\\Local\\Temp\\ipykernel_20940\\2264318532.py:132: FutureWarning:\n",
      "\n",
      "Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "\n",
      "C:\\Users\\PanSt\\AppData\\Local\\Temp\\ipykernel_20940\\2264318532.py:132: FutureWarning:\n",
      "\n",
      "Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "\n",
      "C:\\Users\\PanSt\\AppData\\Local\\Temp\\ipykernel_20940\\2264318532.py:132: FutureWarning:\n",
      "\n",
      "Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "\n",
      "C:\\Users\\PanSt\\AppData\\Local\\Temp\\ipykernel_20940\\2264318532.py:132: FutureWarning:\n",
      "\n",
      "Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "\n",
      "C:\\Users\\PanSt\\AppData\\Local\\Temp\\ipykernel_20940\\1365882306.py:53: DeprecationWarning:\n",
      "\n",
      "Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dash Board\n",
    "app = dash.Dash(__name__)\n",
    "app.config.suppress_callback_exceptions = True\n",
    "\n",
    "# App layout\n",
    "app.layout = html.Div([\n",
    "    html.H1('5F Casino', style={'textAlign': 'center', 'fontSize': 50}),\n",
    "    dcc.Dropdown(\n",
    "        id='main-dropdown',\n",
    "        options=[{'label': year, 'value': year} for year in yearlist],\n",
    "        value=yearlist[0],  # Set the default value\n",
    "        style={'width': '100%'}\n",
    "    ),\n",
    "    dcc.Tabs(\n",
    "        id='tabs',\n",
    "        value='personal',\n",
    "        children=[\n",
    "            dcc.Tab(label='Player Data', value='personal'),\n",
    "            dcc.Tab(label='Table Data', value='global'),\n",
    "        ],\n",
    "        style={'font-size': '24px'},\n",
    "    ),\n",
    "\n",
    "    # Hidden div to store the DataFrame as JSON\n",
    "    dcc.Store(id='df-store', data=df.to_json(orient='split')),\n",
    "    html.Div(id='dummy-input', style={'display': 'none'}), # hidden layer for the dummy-input \n",
    "    html.Div(id='page-content'),\n",
    "])\n",
    "\n",
    "# Callback to switch between subpages\n",
    "@app.callback(Output('page-content', 'children'), Input('tabs', 'value'))\n",
    "def render_content(tab):\n",
    "    if tab == 'personal':\n",
    "        return html.Div([\n",
    "            dcc.Dropdown(\n",
    "                id='Player',\n",
    "                options=[{'label': person, 'value': person} for person in namelist],\n",
    "                value=namelist[0]  # Set the default value\n",
    "            ),\n",
    "            html.Div(id='current-profit'),\n",
    "            dcc.Checklist(id='Comparison-Checklist', value=[], inline=True),\n",
    "            html.H2(\"Session Progress\", style={'text-align': 'center'}),\n",
    "            html.Div(id='session-progress'),\n",
    "            html.H2(\"Monthly Progress\", style={'text-align': 'center'}),\n",
    "            html.Div(id='monthly-progress'),  # Container for the monthly personal data\n",
    "            html.H2(\"All-Time Profit Distribution\", style={'text-align': 'center'}),\n",
    "            html.Div(id='player-profit-distribution'),\n",
    "            html.H2(\"All-Time Player Data\", style={'text-align': 'center'}),\n",
    "            html.Div(id='player-history-table', style={'width':'40%', 'margin':'0 auto'}),\n",
    "            #html.Div(id='gauge-chart'),  # Container for the gauge charts\n",
    "        ])\n",
    "    elif tab == 'global':\n",
    "        return html.Div([\n",
    "            dcc.Dropdown(\n",
    "                id='row-dropdown',\n",
    "                value=0,\n",
    "                style={'width': '100%'}\n",
    "            ),\n",
    "            html.Div(id='results-table-container', style={'margin-bottom': '50px'}),\n",
    "            dcc.Checklist(\n",
    "                id='Name-Checklist',\n",
    "                options=[{'label': person, 'value': person} for person in namelist],\n",
    "                value=namelist[:],  # Select the first 5 people from the namelist\n",
    "                labelStyle={'font-size': '24px',},  # Increase font size and center labels\n",
    "                inline=True,\n",
    "            ),\n",
    "            html.H2(\"Net Profit/Loss\", style={'text-align': 'center'}),\n",
    "            html.Div(id='bar-plot'),\n",
    "            html.H2(\"Time Lapse of Net Profit/Loss\", style={'text-align': 'center'}),\n",
    "            html.Div(id='time-lapse'),\n",
    "            html.H2(id=\"selected-year-text\", children='2024 Table Stats', style={'text-align': 'center'}),\n",
    "            html.Div(id='year-table-stats', style={'width':'50%', 'margin':'0 auto'}),    \n",
    "            html.H2(\"All-Time Table Stats\", style={'text-align': 'center'}),\n",
    "            html.Div(id='all-time-table-stats', style={'width':'50%', 'margin':'0 auto'}),       \n",
    "        ])\n",
    "    \n",
    "# Callback to update the current profit/loss value\n",
    "@app.callback(Output('current-profit', 'children'), [Input('Player', 'value'), Input('main-dropdown', 'value')])\n",
    "def update_current_profit_loss_value(selected_person, selected_year):\n",
    "    fig = Current_profit_loss(selected_person, selected_year, df)\n",
    "    return dcc.Graph(figure=fig)\n",
    "\n",
    "# Callback for updating the checklist\n",
    "@app.callback(Output('Comparison-Checklist', 'options'), Input('Player', 'value'))\n",
    "def update_checklist(selected_player):\n",
    "    remaining_names = [name for name in namelist if name != selected_player] # namelist without the selected name from dcc.Dropdown\n",
    "    checklist_options = [{'label': name, 'value': name} for name in remaining_names]\n",
    "    return checklist_options\n",
    "\n",
    "# Callback for setting the default value to an empty list\n",
    "@app.callback(Output('Comparison-Checklist', 'value'), [Input('Player', 'value')])\n",
    "def update_checklist_default_value(selected_player):\n",
    "    return []\n",
    "\n",
    "# Callback to update the progress per session chart based on the selected person from the dropdown and the player list from the checklist\n",
    "@app.callback(Output('session-progress', 'children'), [Input('Comparison-Checklist', 'value'), Input('Player', 'value'), Input('main-dropdown', 'value')])\n",
    "def update_progress_session_chart(selected_people_checklist, selected_person_dropdown, selected_year):\n",
    "    fig = Progress_Session(selected_people_checklist, selected_person_dropdown, selected_year, df)\n",
    "    return dcc.Graph(figure=fig)\n",
    "\n",
    "# Callback to update the monthly progress chart based on the selected person    \n",
    "@app.callback(Output('monthly-progress', 'children'), [Input('Comparison-Checklist', 'value'), Input('Player', 'value'), Input('main-dropdown', 'value')])\n",
    "def update_progress_montly_chart(selected_people_checklist, selected_person_dropdown, selected_year):\n",
    "    fig = Progress_Monthly(selected_people_checklist, selected_person_dropdown, selected_year, df)\n",
    "    return dcc.Graph(figure=fig)\n",
    "\n",
    "# Callback to update the monthly progress chart based on the selected person    \n",
    "@app.callback(Output('player-profit-distribution', 'children'), [Input('Comparison-Checklist', 'value'), Input('Player', 'value')])\n",
    "def update_player_disrtribution(selected_people_checklist, selected_person_dropdown):\n",
    "    fig = get_distribution(selected_people_checklist, selected_person_dropdown, df)\n",
    "    return dcc.Graph(figure=fig)\n",
    "\n",
    "# Callback to update the player history based on the selected person  \n",
    "@app.callback(Output('player-history-table', 'children'), Input('Player', 'value'))\n",
    "def update_player_history(selected_person):\n",
    "    fig = player_history(selected_person, df)\n",
    "    return fig\n",
    "\n",
    "# Callback to update the gauge charts based on the selected person  \n",
    "@app.callback(Output('gauge-chart', 'children'), [Input('Player', 'value'), Input('main-dropdown', 'value')])\n",
    "def update_gauge_charts(selected_person, selected_year):\n",
    "    fig = Gauge_Charts(selected_person, selected_year, df)\n",
    "    return dcc.Graph(figure=fig)\n",
    "\n",
    "################################################################################\n",
    "\n",
    "# Callback for the game dropdown\n",
    "@app.callback([Output('row-dropdown', 'options'), Output('row-dropdown', 'value')], [Input('main-dropdown', 'value')], [State('df-store', 'data')])\n",
    "def update_game_dropdown(selected_year, df_json):\n",
    "\n",
    "    # Convert the JSON data back to a DataFrame\n",
    "    df = pd.read_json(df_json, orient='split')\n",
    "    \n",
    "    df, dftime, dftime2, dftime3 = df_selected_year(df=df, selected_year=selected_year)\n",
    "    updated_options = [{'label': '{1} - Session {0}'.format(i+1, pd.to_datetime(dftime2.index.values[i], format='%d/%m/%Y').strftime('%d-%b')), 'value': i} for i in range(dftime2.shape[0])]\n",
    "    updated_value = dftime2.shape[0] - 1  # Default to the last game\n",
    "    return updated_options, updated_value\n",
    "\n",
    "# Callback to update the table based on the selected row\n",
    "@app.callback(Output('results-table-container', 'children'), [Input('row-dropdown', 'value'), Input('main-dropdown', 'value')])\n",
    "def update_table(selected_row, selected_year):\n",
    "    fig = make_table(selected_row, selected_year, df)\n",
    "    return fig\n",
    "\n",
    "# Callback to update the current progress bar chart based on the selected people (from the checklist)\n",
    "@app.callback(Output('bar-plot', 'children'), [Input('Name-Checklist', 'value'), Input('main-dropdown', 'value')])\n",
    "def update_graph(selected_people, selected_year):\n",
    "    fig = Status_bar(selected_people, selected_year, df)\n",
    "    return dcc.Graph(figure=fig)\n",
    "\n",
    "# Callback to update the current time lapse bar chart based on the selected people (from the checklist)\n",
    "@app.callback(Output('time-lapse', 'children'), [Input('Name-Checklist', 'value'), Input('main-dropdown', 'value')])\n",
    "def update_graph(selected_people, selected_year):\n",
    "    fig = Time_Lapse(selected_people, selected_year, df)\n",
    "    return dcc.Graph(figure=fig)\n",
    "\n",
    "# Callback to update the H2 header\n",
    "@app.callback(Output('selected-year-text', 'children'), Input('main-dropdown', 'value'))\n",
    "def update_header_text(selected_year):\n",
    "    return '{} Table Stats'.format(selected_year)\n",
    "\n",
    "# Callback to update the table stats based on the selected year  \n",
    "@app.callback(Output('year-table-stats', 'children'), Input('main-dropdown', 'value'))\n",
    "def update_all_time_table_stats(selected_year):\n",
    "    fig = year_table_stats(selected_year, df)\n",
    "    return fig\n",
    "\n",
    "# Callback to update the all-time table stats\n",
    "@app.callback(Output('all-time-table-stats', 'children'), Input('dummy-input', 'children'))\n",
    "def update_all_time_table_stats(dummy_input):\n",
    "    fig = all_time_table_stats(df)\n",
    "    return fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, port=8060)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
